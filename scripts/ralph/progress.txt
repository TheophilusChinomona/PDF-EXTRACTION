# Ralph Progress Log

Started: 2026-01-28
Project: PDF-Extraction (Hybrid Architecture)
Branch: ralph/hybrid-extraction-pipeline

---

## Codebase Patterns

- **Gemini SDK:** Use `from google import genai` (modern SDK), NOT `google.generativeai`
- **Settings Pattern:** Use `get_settings()` for configuration access (singleton via @lru_cache)
- **Testing Settings:** Always call `get_settings.cache_clear()` before testing environment variables
- **Pydantic v2:** Raises `ValidationError` for validation failures (not `ValueError`)
- **Mypy Configuration:** Requires `plugins = pydantic.mypy` in mypy.ini for BaseSettings support

---

## 2026-01-28 03:30 - US-001
- Implemented Python project structure and configuration
- Created directory structure: app/, app/routers/, app/services/, app/models/, app/db/, tests/
- Created .gitignore with Python, venv, and project-specific exclusions
- Created .env.example with API key placeholders
- Created __init__.py files in all Python packages
- Created comprehensive README.md with setup instructions and architecture overview

**Files changed:**
- Created: .gitignore, .env.example, README.md
- Created: app/__init__.py, app/routers/__init__.py, app/services/__init__.py, app/models/__init__.py, app/db/__init__.py, tests/__init__.py

**Learnings for future iterations:**
- Project follows standard Python package structure with clear separation of concerns
- All configuration should go through environment variables (.env file)
- Empty __init__.py files are needed to make directories valid Python packages
- .gitignore must include .env to prevent accidental secret commits

---

## 2026-01-28 04:00 - US-002
- Implemented requirements.txt with all project dependencies
- Added core dependencies: opendataloader-pdf (>=1.0.0), google-genai (>=0.3.0 - modern SDK)
- Added FastAPI ecosystem: fastapi (>=0.100.0), uvicorn (>=0.23.0)
- Added database client: supabase-py (>=2.0.0)
- Added data validation: pydantic (>=2.0.0), pydantic-settings (>=2.0.0)
- Added file handling utilities: python-multipart, python-dotenv, python-magic, httpx
- Added testing framework: pytest, pytest-asyncio, pytest-cov
- Installation already documented in README.md

**Files changed:**
- Created: requirements.txt
- Updated: scripts/ralph/prd.json (marked US-002 as passes: true)

**Learnings for future iterations:**
- Use google-genai (modern SDK) NOT google-generativeai (legacy)
- All dependencies have minimum version constraints (>=) for compatibility
- Test dependencies are included in requirements.txt for CI/CD setup
- README.md already contained installation instructions from US-001

---

## 2026-01-28 05:00 - US-003
- Implemented centralized configuration with Pydantic Settings
- Created app/config.py with Settings class extending pydantic_settings.BaseSettings
- Added configuration fields: gemini_api_key, supabase_url, supabase_key, model_name (default: gemini-3-flash-preview), enable_hybrid_mode (default: True)
- Implemented field validators for GEMINI_API_KEY, SUPABASE_URL, and SUPABASE_KEY with detailed error messages
- Created get_settings() function with @lru_cache for singleton pattern
- Fixed requirements.txt: corrected package name from supabase-py to supabase
- Created comprehensive test suite in tests/test_config.py with 13 tests covering:
  - Valid configuration loading
  - Custom configuration values
  - Missing/empty/whitespace-only API keys validation
  - Invalid Supabase URL validation (must be HTTPS)
  - Settings caching behavior
- All tests pass, typecheck passes with mypy

**Files changed:**
- Created: app/config.py, tests/test_config.py
- Updated: requirements.txt (supabase-py → supabase)
- Updated: scripts/ralph/prd.json (marked US-003 as passes: true)

**Learnings for future iterations:**
- Use pydantic_settings.BaseSettings for environment variable loading (not pydantic.BaseSettings)
- Field validators should use @field_validator decorator with @classmethod
- Settings.model_config uses SettingsConfigDict (not nested Config class in Pydantic v2)
- Always validate credentials at startup to fail fast with clear error messages
- The Supabase Python package is named 'supabase' not 'supabase-py'
- Use @lru_cache on settings getter to ensure singleton pattern across the app
- Validators should strip whitespace from user inputs for better UX

---

## 2026-01-28 06:00 - US-004
- Implemented Gemini API client initialization with error handling
- Created app/services/gemini_client.py with get_gemini_client() function
- Uses modern google-genai SDK (from google import genai)
- Returns genai.Client initialized with API key from settings
- Clear error messages for missing GEMINI_API_KEY
- Created mypy.ini configuration file with Pydantic plugin support
- Created comprehensive test suite in tests/test_gemini_client.py
- All 5 tests pass covering:
  - Successful client initialization with valid API key
  - Missing API key raises ValidationError (Pydantic v2)
  - Empty API key raises ValidationError
  - Whitespace-only API key raises ValidationError
  - Client instance is returned correctly
- Typecheck passes with mypy

**Files changed:**
- Created: app/services/gemini_client.py, tests/test_gemini_client.py, mypy.ini
- Updated: scripts/ralph/prd.json (marked US-004 as passes: true)

**Learnings for future iterations:**
- Use 'from google import genai' NOT 'google.generativeai' (modern SDK)
- Pydantic v2 raises ValidationError (not ValueError) for missing required fields
- MagicMock(spec=SomeClass) fails if SomeClass is already mocked - just use MagicMock() without spec
- Need mypy.ini with 'plugins = pydantic.mypy' to handle BaseSettings() calls correctly
- Settings validation happens automatically when get_settings() is called, before reaching get_gemini_client()
- Tests should clear get_settings.cache_clear() to force re-validation when testing environment variables

---

## 2026-01-28 07:00 - US-005
- Implemented Pydantic models for PDF extraction results
- Created app/models/extraction.py with 7 model classes:
  - BoundingBox: PDF coordinates (x1, y1, x2, y2, page) with page >= 1 validation
  - ExtractedMetadata: Bibliographic info with year range validation (1900-2100)
  - ExtractedSection: Document sections with heading, content, page, optional bbox
  - ExtractedTable: Tables with caption, data (List[dict]), page, optional bbox
  - ExtractedReference: Parsed references with citation text, authors, year, title
  - DocumentStructure: OpenDataLoader output (markdown, tables, bboxes, quality_score 0-1, element_count)
  - ExtractionResult: Final pipeline output with metadata, abstract, sections, tables, references, confidence_score 0-1, bounding_boxes dict, processing_metadata dict
- Created comprehensive test suite: tests/test_extraction_models.py with 20 tests
- All tests cover validation, defaults, field constraints, and edge cases
- Tests pass (20/20), typecheck passes with --strict mode

**Files changed:**
- Created: app/models/extraction.py, tests/test_extraction_models.py
- Updated: scripts/ralph/prd.json (marked US-005 as passes: true)

**Learnings for future iterations:**
- Pydantic Field() allows ge/le constraints for numeric validation (e.g., confidence_score between 0-1)
- default_factory=list/dict prevents mutable default arguments bug
- Optional[T] with default=None is correct pattern for nullable fields
- BaseModel with Field(description=...) provides self-documenting schemas
- Use Dict[str, BoundingBox] not dict[str, BoundingBox] for Python 3.8 compatibility (though typing.Dict is preferred)
- Field validators automatically run on model instantiation - no need for custom __init__

---

## 2026-01-28 08:00 - US-006
- Implemented OpenDataLoader PDF structure extraction
- Created app/services/opendataloader_extractor.py with extract_pdf_structure() function
- Uses opendataloader_pdf.convert() to generate JSON and Markdown output files
- Extracts markdown representation, tables with bounding boxes, and element bounding boxes
- Returns DocumentStructure model with quality_score placeholder (calculated in US-007)
- Created comprehensive test suite: tests/test_opendataloader_extractor.py with 11 tests
- All tests pass (11/11)

**Files changed:**
- Created: app/services/opendataloader_extractor.py, tests/test_opendataloader_extractor.py
- Updated: scripts/ralph/prd.json (marked US-006 as passes: true)

**Learnings for future iterations:**
- OpenDataLoader API uses functional `convert()` not object-oriented `DocumentLoader()` class
- The convert() function writes JSON/Markdown files to disk - must read them to extract data
- JSON structure has "elements" array with type, page, text, bbox, and optional table_data fields
- Pydantic models auto-convert dict inputs to typed objects (e.g., Dict[str, BoundingBox])
- When testing Pydantic models, access BoundingBox attributes (bbox.x1) not dict keys (bbox["x1"])
- Use tempfile.TemporaryDirectory() context manager to clean up output files automatically
- OpenDataLoader requires quiet=True parameter to suppress console output during conversion
---

## 2026-01-28 09:00 - US-007
- Implemented quality scoring for routing decisions in hybrid extraction pipeline
- Created calculate_quality_score() function with weighted scoring criteria:
  - Text completeness (40%): >1000 chars = 0.4, >500 = 0.3, >100 = 0.2
  - Structure detection (30%): >50 elements = 0.3, >20 = 0.2, >5 = 0.1
  - Heading hierarchy (15%): >=5 headings = 0.15, >=3 = 0.1, >=1 = 0.05
  - Table extraction (15%): valid tables (>3 rows) = 0.15, some tables = 0.1
- Updated extract_pdf_structure() to calculate and include quality_score in result
- Score is capped at 1.0 using min(score, 1.0)
- Created comprehensive test suite with 16 new tests covering:
  - All scoring thresholds and boundary conditions
  - Realistic high-quality and low-quality PDF scenarios
  - Edge cases (empty documents, mixed table quality)
  - Floating-point precision handling
- All 27 tests pass, typecheck passes with mypy --strict

**Files changed:**
- Updated: app/services/opendataloader_extractor.py (added calculate_quality_score function)
- Updated: tests/test_opendataloader_extractor.py (added 16 quality scoring tests)
- Updated: scripts/ralph/prd.json (marked US-007 as passes: true)

**Learnings for future iterations:**
- Quality score determines routing: <0.7 triggers Vision fallback, >=0.7 uses hybrid mode
- Valid tables are defined as having >3 rows to filter out single-row artifacts
- Floating-point arithmetic requires approximate comparisons in tests (use abs(a - b) < 0.001)
- Quality scoring is now integrated into extract_pdf_structure() - no separate call needed
- The quality_score field in DocumentStructure is no longer a placeholder
---

## 2026-01-28 10:00 - US-008
- Implemented hybrid extraction pipeline combining OpenDataLoader and Gemini API
- Created app/services/pdf_extractor.py with extract_pdf_data_hybrid() function
- Implemented 6-step pipeline:
  1. Extract PDF structure locally using OpenDataLoader
  2. Route based on quality_score threshold (0.7)
  3. Build prompt with structured markdown content for Gemini
  4. Call Gemini API with response_schema=ExtractionResult for structured output
  5. Merge OpenDataLoader tables (more reliable) with Gemini semantic data
  6. Add processing_metadata tracking method, quality scores, cost savings (80%)
- Created stub for extract_with_vision_fallback() to be implemented in US-009
- Created comprehensive test suite: tests/test_pdf_extractor.py with 9 tests
- All tests pass (9/9), typecheck passes with mypy --strict

**Files changed:**
- Created: app/services/pdf_extractor.py (136 lines)
- Created: tests/test_pdf_extractor.py (345 lines)
- Updated: scripts/ralph/prd.json (marked US-008 as passes: true)

**Learnings for future iterations:**
- Gemini API generate_content accepts `contents=str` directly (not `contents=[str]`)
- response.parsed returns union type - must type-check with isinstance() before assigning
- Quality threshold at 0.7 determines routing: >=0.7 uses hybrid, <0.7 triggers fallback
- OpenDataLoader tables should replace Gemini tables (deterministic extraction is more reliable)
- Bounding boxes from OpenDataLoader are preserved via Pydantic auto-conversion (dict → BoundingBox)
- Processing metadata should track: method, quality scores, cost savings, element count, model used
- Vision fallback (US-009) will handle low-quality PDFs with quality_score < 0.7
- Async function signature required even though OpenDataLoader is synchronous (for future async Gemini calls)
---

## 2026-01-28 11:00 - US-009
- Implemented Vision fallback for low-quality PDFs (quality_score < 0.7)
- Created extract_with_vision_fallback() function in app/services/pdf_extractor.py
- Implemented file upload via client.files.upload(file=file_path)
- Sends uploaded file + extraction prompt to Gemini API with response_schema=ExtractionResult
- Added cleanup logic in finally block: client.files.delete(name=uploaded_file.name)
- Cleanup is resilient: errors don't prevent result from being returned
- Added processing_metadata: {'method': 'vision_fallback', 'reason': 'Low OpenDataLoader quality score', 'cost_savings_percent': 0}
- Updated 3 existing tests to work with implemented fallback (removed NotImplementedError expectations)
- Created 6 new comprehensive tests covering:
  - Successful Vision extraction with file upload and cleanup
  - Cleanup on success and on error (via finally block)
  - No cleanup attempt if upload fails
  - Silent cleanup failures (don't raise)
  - Custom model parameter support
- All 14 tests pass (6 Vision fallback + 8 hybrid extraction)
- Typecheck passes with mypy --strict

**Files changed:**
- Updated: app/services/pdf_extractor.py (implemented extract_with_vision_fallback, 70 lines)
- Updated: tests/test_pdf_extractor.py (replaced stub test, added 6 Vision tests, updated 3 hybrid tests)
- Updated: scripts/ralph/prd.json (marked US-009 as passes: true)

**Learnings for future iterations:**
- Gemini Files API: client.files.upload(file=path) returns object with .name attribute
- Vision mode requires contents=[uploaded_file, prompt] - list with file object first
- Always use finally block for cleanup to ensure resources are freed even on errors
- Use try/except in finally to silence cleanup failures (extraction result is more important)
- Mypy strict mode: check hasattr() and truthiness for Optional attributes (uploaded_file.name)
- Vision fallback has 0% cost savings (full Vision API cost), unlike hybrid mode (80% savings)
- Test mocking pattern: Mock file upload, API response, and cleanup to verify complete flow
- Update dependent tests when removing stubs - check for NotImplementedError expectations
---

## 2026-01-28 12:00 - US-010
- Implemented file upload validation with security checks
- Created app/services/file_validator.py with validate_pdf() async function
- Implemented size validation (max 200MB, returns 413 if exceeded)
- Implemented empty file check (returns 400 if 0 bytes)
- Implemented MIME type validation using python-magic (must be 'application/pdf')
- Created sanitize_filename() function that:
  - Removes path traversal attempts (../, ..\, etc.)
  - Strips directory paths using Path(filename).name
  - Removes null bytes and special characters
  - Ensures .pdf extension is present
  - Limits filename length to 255 characters
- Implemented SHA-256 hash calculation for deduplication
- Returns tuple: (content: bytes, file_hash: str, sanitized_filename: str)
- Created comprehensive test suite: tests/test_file_validator.py with 20 tests
- All tests pass (20/20), typecheck passes with mypy --strict
- Added python-magic-bin to requirements.txt for Windows compatibility

**Files changed:**
- Created: app/services/file_validator.py (120 lines)
- Created: tests/test_file_validator.py (281 lines)
- Updated: requirements.txt (added python-magic-bin for Windows)
- Updated: scripts/ralph/prd.json (marked US-010 as passes: true)

**Learnings for future iterations:**
- python-magic requires python-magic-bin on Windows to provide the libmagic DLL
- Add platform-specific dependencies in requirements.txt using sys_platform marker
- Path(filename).name is best practice for extracting base filename and preventing path traversal
- Sanitize filenames AFTER extracting base name, not before (more effective)
- FastAPI UploadFile.read() is async - must use await
- HTTPException with status_code and detail is FastAPI's standard error pattern
- Tuple return types work well for multi-value validation results
- File hash (SHA-256) enables deduplication checks before processing
- Test both boundary conditions (exactly 200MB passes, 200MB+1 fails)
---

## 2026-01-28 13:00 - US-011
- Implemented Supabase client initialization with error handling
- Created app/db/supabase_client.py with get_supabase_client() function
- Uses supabase.create_client(url, key) to initialize client
- Credentials loaded from Settings model (SUPABASE_URL, SUPABASE_KEY)
- Validation handled by Settings validators - raises ValidationError if missing/invalid
- Wraps create_client exceptions with clear error messages
- Created comprehensive test suite: tests/test_supabase_client.py with 11 tests
- All tests pass (11/11), typecheck passes with mypy --strict

**Files changed:**
- Created: app/db/supabase_client.py (38 lines)
- Created: tests/test_supabase_client.py (217 lines)
- Updated: scripts/ralph/prd.json (marked US-011 as passes: true)

**Learnings for future iterations:**
- Import pattern: from supabase import create_client, Client
- create_client(url, key) returns Client object with .table() and other methods
- Credentials validation happens in Settings model before get_supabase_client is called
- Test pattern: Mock create_client to avoid actual network calls
- Client return type is Client from supabase package
- Errors from create_client should be wrapped with ValueError for clarity
- Supabase package has deprecation warning for gotrue (migrate to supabase_auth in future)
---

## 2026-01-28 14:00 - US-012
- Implemented database schema migration for extractions table
- Created migrations/001_create_extractions_table.sql (113 lines)
- Created enum types: extraction_status (pending, completed, failed, partial) and processing_method_type (hybrid, vision_fallback, opendataloader_only)
- Created extractions table with UUID primary key
- Added file metadata columns: file_name, file_size_bytes, file_hash (unique index)
- Added processing columns: status, processing_method, quality_score (0-1), confidence_score (0-1)
- Added JSONB columns for structured data: metadata, sections, figures, tables, references, bounding_boxes
- Added text columns: abstract, error_message
- Added performance tracking: processing_time_seconds, cost_estimate_usd, retry_count (default 0)
- Added timestamps: created_at (default NOW()), updated_at (auto-updated via trigger)
- Added webhook_url for optional notification callbacks
- Created indexes: unique file_hash, status, created_at DESC, processing_method, composite status+created_at
- Added comprehensive documentation via COMMENT statements for all columns
- Fixed typecheck issue in pdf_extractor.py: added explicit type hint for contents parameter in Vision fallback
- All 110 tests pass, mypy --strict passes

**Files changed:**
- Created: migrations/001_create_extractions_table.sql
- Updated: app/services/pdf_extractor.py (typecheck fix)
- Updated: scripts/ralph/prd.json (marked US-012 as passes: true)

**Learnings for future iterations:**
- SQL migrations should use IF NOT EXISTS for idempotency
- Enum types must be created before referencing them in CREATE TABLE
- DECIMAL(4,3) provides 0.000-1.000 precision for scores (4 total digits, 3 after decimal)
- CHECK constraints validate data integrity at database level
- Unique indexes serve dual purpose: enforce uniqueness + optimize lookups
- Composite indexes (status, created_at) optimize common query patterns (e.g., "get recent completed extractions")
- UPDATE trigger with NOW() keeps updated_at synchronized automatically
- COMMENT statements document schema intent for future developers
- JSONB columns allow flexible schema for extracted content while maintaining SQL query capabilities
- Mypy strict mode requires explicit typing for list literals passed to complex union type parameters
---

## 2026-01-28 15:00 - US-013
- Implemented database storage functions for extraction records in Supabase
- Created app/db/extractions.py with 5 core CRUD functions:
  - create_extraction(): Inserts extraction result with file metadata, returns UUID
  - get_extraction(): Retrieves extraction by UUID, returns dict or None
  - check_duplicate(): Checks for duplicate PDFs by file hash, enables deduplication
  - update_extraction_status(): Updates status (pending/completed/failed/partial) with optional error message
  - list_extractions(): Lists extractions with pagination (limit/offset) and status filtering
- All functions are async, have full type hints, and include comprehensive validation
- UUID validation raises ValueError for invalid formats
- Status validation ensures only valid enum values ('pending', 'completed', 'failed', 'partial')
- Database errors are caught and re-raised with clear context messages
- Created comprehensive test suite: tests/test_extractions.py with 24 tests
- All 134 tests pass (including 24 new extraction tests), mypy --strict passes
- Fixed mypy type checking: explicit type cast for dict return values

**Files changed:**
- Created: app/db/extractions.py (210 lines)
- Created: tests/test_extractions.py (398 lines)
- Updated: scripts/ralph/prd.json (marked US-013 as passes: true)

**Learnings for future iterations:**
- Supabase Python client uses method chaining: client.table('name').select().eq().execute()
- response.execute() returns object with .data attribute (list of dicts)
- Empty result sets return response.data = [] or None, not an exception
- UUID validation pattern: wrap UUID() constructor in try/except to catch ValueError
- Status enums should be validated before passing to database to prevent SQL errors
- Mypy strict mode: explicit type cast (result: Dict[str, Any] = data[0]) prevents no-any-return errors
- When testing Supabase queries, mock the full chain: table().select().eq().execute()
- Pagination: range(offset, offset + limit - 1) is correct Supabase pattern
- Async function signatures required even though Supabase client is synchronous (for consistency)
- Model.model_dump() converts Pydantic models to dicts for JSON storage
---


## 2026-01-28 16:00 - US-014
- Implemented FastAPI application with health check and version endpoints
- Created app/main.py with FastAPI app instance
- Added CORS middleware with configurable origins (default: all origins)
- Implemented GET /health endpoint that checks:
  - OpenDataLoader availability (import test)
  - Gemini API client initialization
  - Supabase database connection (test query)
- Health endpoint returns 200 if all services healthy, 503 if any fail
- Health response includes status, timestamp, and individual service statuses
- Implemented GET /version endpoint returning version number and commit hash
- Used modern lifespan event handler (replaced deprecated @app.on_event)
- Lifespan handler validates environment configuration on startup
- Enabled Swagger documentation at /docs and ReDoc at /redoc
- Created comprehensive test suite: tests/test_main.py with 14 tests
- All 148 tests pass (including existing tests), mypy --strict passes

**Files changed:**
- Created: app/main.py (140 lines)
- Created: tests/test_main.py (259 lines)
- Updated: scripts/ralph/prd.json (marked US-014 as passes: true)

**Learnings for future iterations:**
- FastAPI doesn't support Union[Dict, Response] return types - must use response_model=None
- Modern FastAPI uses @asynccontextmanager lifespan handlers instead of @app.on_event
- Lifespan pattern: async with context manager that yields for startup/shutdown
- Health checks should test actual connectivity (database query) not just imports
- Response object requires explicit status_code parameter (can't use decorator status_code)
- Import json module when manually creating Response with JSON content
- TestClient automatically triggers lifespan events when used as context manager
- FastAPI provides /openapi.json schema automatically at root
- datetime.utcnow() is deprecated - should use datetime.now(datetime.UTC) in future
- CORS middleware should be restrictive in production (use explicit allow_origins list)
---

## 2026-01-28 17:00 - US-015
- Implemented PDF extraction API endpoint (POST /api/extract)
- Created app/routers/extraction.py with complete extraction workflow:
  1. File validation using validate_pdf() (size, MIME type, hash)
  2. Duplicate detection via file_hash using check_duplicate()
  3. Temporary file handling with automatic cleanup (finally block)
  4. Hybrid extraction via extract_pdf_data_hybrid()
  5. Database storage via create_extraction()
  6. X-Extraction-ID header in response
- Integrated router into app/main.py
- Implemented comprehensive error handling:
  - 400: Validation errors (invalid file)
  - 413: File too large (>200MB)
  - 422: Corrupted PDF or Pydantic validation failure
  - 500: Processing or database errors
- Returns 201 Created for new extractions, 200 OK for duplicates
- Created comprehensive test suite with 12 tests (100% pass rate)
- All 160 tests pass, mypy --strict passes

**Files changed:**
- Created: app/routers/extraction.py (153 lines)
- Updated: app/main.py (registered extraction router)
- Created: tests/test_extraction_router.py (12 tests)
- Updated: scripts/ralph/prd.json (marked US-015 as passes: true)

**Learnings for future iterations:**
- Import functions at module level, not inside functions, to enable proper test mocking
- FastAPI routers use APIRouter(prefix="/api") to set base path
- Use Response object to set custom status codes and headers (X-Extraction-ID)
- Pydantic model.model_dump_json() serializes to JSON string for Response content
- Use finally block for file cleanup to ensure temp files removed even on errors
- Duplicate detection returns existing result with 200 status (not 201)
- Test pattern: Mock external dependencies at module level (validate_pdf, get_supabase_client, etc.)
- AsyncMock for async functions, MagicMock for sync functions
- File cleanup errors should be silently caught (extraction result more important)
- TestClient from fastapi.testclient automatically triggers lifespan events
---
