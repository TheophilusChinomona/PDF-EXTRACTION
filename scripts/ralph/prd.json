{
  "project": "PDF-Extraction",
  "branchName": "ralph/hybrid-extraction-pipeline",
  "description": "Academic PDF Extraction Microservice with Hybrid Architecture (OpenDataLoader + Gemini) - 80% cost reduction, 95% accuracy, bounding boxes for citations",
  "completedStories": [
    {"id": "US-001", "title": "Create Python project structure and configuration", "passes": true},
    {"id": "US-002", "title": "Create requirements.txt with all dependencies", "passes": true},
    {"id": "US-003", "title": "Create Pydantic config with environment variable loading", "passes": true},
    {"id": "US-004", "title": "Create Gemini client initialization with error handling", "passes": true},
    {"id": "US-005", "title": "Create Pydantic models for extraction results", "passes": true},
    {"id": "US-006", "title": "Implement OpenDataLoader PDF structure extraction", "passes": true},
    {"id": "US-007", "title": "Implement quality scoring for routing decisions", "passes": true},
    {"id": "US-008", "title": "Implement hybrid extraction pipeline (OpenDataLoader + Gemini)", "passes": true},
    {"id": "US-009", "title": "Implement Vision fallback for low-quality PDFs", "passes": true},
    {"id": "US-010", "title": "Implement file upload validation", "passes": true},
    {"id": "US-011", "title": "Create Supabase client initialization", "passes": true},
    {"id": "US-012", "title": "Create database schema migration for extractions table", "passes": true},
    {"id": "US-013", "title": "Implement database storage functions for extractions", "passes": true},
    {"id": "US-014", "title": "Create FastAPI app with health check endpoint", "passes": true},
    {"id": "US-015", "title": "Create PDF extraction endpoint (POST /extract)", "passes": true},
    {"id": "US-016", "title": "Create extraction retrieval endpoint (GET /extractions/{id})", "passes": true},
    {"id": "US-017", "title": "Create bounding box retrieval endpoints", "passes": true},
    {"id": "US-018", "title": "Implement retry logic with exponential backoff", "passes": true},
    {"id": "US-019", "title": "Implement partial result storage", "passes": true},
    {"id": "US-020", "title": "Add request logging and metrics", "passes": true},
    {"id": "US-021", "title": "Add rate limiting middleware", "passes": true}
  ],
  "userStories": [
    {
      "id": "US-022",
      "title": "Create manual review queue for failed extractions",
      "description": "As a data quality manager, I need failed extractions queued for manual review.",
      "acceptanceCriteria": [
        "Create migrations/002_create_review_queue_table.sql",
        "Create table: review_queue with UUID id, extraction_id (FK), error_type, error_message",
        "Add: processing_method, quality_score, retry_count, queued_at, reviewed_at (nullable), reviewer_notes (nullable)",
        "Add resolution enum: fixed, false_positive, unable_to_process",
        "Update extraction endpoint: when retry_count > 5, add to review_queue",
        "Add GET /review-queue endpoint (returns pending items)",
        "Add POST /review-queue/{id}/resolve endpoint (marks as reviewed)",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 22,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-023",
      "title": "Implement batch processing endpoint",
      "description": "As a researcher, I need to upload multiple PDFs for batch processing.",
      "acceptanceCriteria": [
        "Create migrations/003_create_batch_jobs_table.sql",
        "Create table: batch_jobs with UUID id, total_files, completed_files, failed_files, status",
        "Add JSONB: routing_stats {hybrid, vision_fallback, pending}, extraction_ids (array)",
        "Add: created_at, estimated_completion, cost_estimate_usd, cost_savings_usd, webhook_url",
        "Add POST /batch endpoint accepting multiple files (max 100)",
        "Generate batch_job_id, store in database",
        "Process each file through hybrid pipeline (can be synchronous for MVP)",
        "Update batch_jobs.routing_stats as files complete",
        "Return 202 with batch_job_id and status URL",
        "Add GET /batch/{job_id} endpoint for status checking",
        "Typecheck passes",
        "Tests pass (small batch of 3-5 files)"
      ],
      "priority": 23,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-024",
      "title": "Implement webhook notifications",
      "description": "As an API consumer, I need webhook notifications when extraction completes.",
      "acceptanceCriteria": [
        "Create app/services/webhook_sender.py",
        "Implement send_webhook(webhook_url, payload, signature_key) function",
        "Validate webhook_url is HTTPS (reject HTTP)",
        "Generate HMAC-SHA256 signature of payload",
        "Add X-Webhook-Signature header",
        "POST payload to webhook_url with 30s timeout",
        "Retry on failure: 3 retries with exponential backoff",
        "Log webhook delivery attempts and responses",
        "Call send_webhook after successful extraction if webhook_url provided",
        "Payload format: {event: 'extraction.completed', extraction_id, status, data, timestamp}",
        "Typecheck passes",
        "Tests pass (with mock webhook server)"
      ],
      "priority": 24,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-025",
      "title": "Implement context caching for cost optimization",
      "description": "As a cost-conscious operator, I need Gemini context caching to reduce API costs by 90%.",
      "acceptanceCriteria": [
        "Update pdf_extractor.py to use context caching",
        "Cache system instruction prompt for academic PDF analysis",
        "Set cache TTL to 1 hour",
        "Track cache hits/misses in processing_metadata",
        "Calculate cost savings: add cached_tokens_saved to metadata",
        "Log cache statistics per request",
        "Add GET /stats/caching endpoint showing cache hit rate and savings",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 25,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-026",
      "title": "Add routing statistics dashboard endpoint",
      "description": "As an operator, I need to see routing distribution and cost savings metrics.",
      "acceptanceCriteria": [
        "Add GET /stats/routing endpoint",
        "Query extractions table: count by processing_method",
        "Calculate average quality_score",
        "Calculate total_cost_usd, estimated_pure_vision_cost_usd, total_savings_usd, savings_percent",
        "Calculate performance metrics: avg_processing_time_seconds, p95_processing_time",
        "Return JSON with all metrics",
        "Cache results for 5 minutes to reduce database load",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 26,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-027",
      "title": "Create integration tests for end-to-end extraction flow",
      "description": "As a developer, I need integration tests to verify the complete extraction pipeline works.",
      "acceptanceCriteria": [
        "Create tests/integration/test_extraction_flow.py",
        "Test: upload PDF → extract (hybrid) → store → retrieve → verify bounding boxes",
        "Test: upload scanned PDF → fallback to Vision → store → retrieve",
        "Test: upload duplicate PDF → return cached result",
        "Test: upload invalid file → return 400 error",
        "Test: batch processing with 3 PDFs → verify all complete",
        "Test: webhook delivery after extraction",
        "Use pytest fixtures for: test PDFs, mock Gemini client, test Supabase instance",
        "Tests pass",
        "Coverage > 80% for core extraction flow"
      ],
      "priority": 27,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-028",
      "title": "Create deployment documentation and Docker configuration",
      "description": "As a DevOps engineer, I need deployment instructions and containerization.",
      "acceptanceCriteria": [
        "Create Dockerfile: FROM python:3.11-slim",
        "Install dependencies from requirements.txt",
        "Set working directory to /app",
        "Copy app code",
        "Expose port 8000",
        "CMD: uvicorn app.main:app --host 0.0.0.0 --port 8000",
        "Create docker-compose.yml for local development (includes app service)",
        "Create DEPLOYMENT.md with: environment setup, Docker build/run, environment variables, health check verification",
        "Document Supabase setup steps (create project, run migrations)",
        "Document how to get Gemini API key",
        "All documentation clear and tested"
      ],
      "priority": 28,
      "passes": false,
      "notes": ""
    }
  ]
}
