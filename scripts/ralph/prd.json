{
  "project": "PDF-Extraction",
  "branchName": "ralph/hybrid-extraction-pipeline",
  "description": "Academic PDF Extraction Microservice with Hybrid Architecture (OpenDataLoader + Gemini) - 80% cost reduction, 95% accuracy, bounding boxes for citations",
  "userStories": [
    {
      "id": "US-001",
      "title": "Create Python project structure and configuration",
      "description": "As a developer, I need a properly configured Python project structure with virtual environment setup.",
      "acceptanceCriteria": [
        "Create project directories: app/, app/routers/, app/services/, app/models/, app/db/, tests/",
        "Create .gitignore with: .env, __pycache__/, venv/, *.pyc, .pytest_cache/, *.egg-info/",
        "Create .env.example with placeholders: GEMINI_API_KEY, SUPABASE_URL, SUPABASE_KEY",
        "Create empty __init__.py files in app/ and subdirectories",
        "Create README.md with basic project description and setup instructions",
        "Typecheck passes"
      ],
      "priority": 1,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-002",
      "title": "Create requirements.txt with all dependencies",
      "description": "As a developer, I need all required Python packages listed so the environment can be set up.",
      "acceptanceCriteria": [
        "Create requirements.txt with: opendataloader-pdf>=1.0.0",
        "Add: google-genai>=0.3.0 (modern SDK, not google-generativeai)",
        "Add: fastapi>=0.100.0, uvicorn>=0.23.0",
        "Add: supabase-py>=2.0.0",
        "Add: pydantic>=2.0.0, pydantic-settings>=2.0.0",
        "Add: python-multipart>=0.0.6, python-dotenv>=1.0.0, python-magic>=0.4.27, httpx>=0.24.0",
        "Add test dependencies: pytest>=7.4.0, pytest-asyncio>=0.21.0, pytest-cov>=4.1.0",
        "Document in README how to install: pip install -r requirements.txt"
      ],
      "priority": 2,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-003",
      "title": "Create Pydantic config with environment variable loading",
      "description": "As a developer, I need centralized configuration that loads from environment variables.",
      "acceptanceCriteria": [
        "Create app/config.py with Settings class using pydantic_settings.BaseSettings",
        "Settings fields: gemini_api_key (str), supabase_url (str), supabase_key (str), model_name (str, default='gemini-3-flash-preview'), enable_hybrid_mode (bool, default=True)",
        "Settings.Config: env_file = '.env'",
        "Validate GEMINI_API_KEY is present on startup (raise ValueError if missing)",
        "Add type hints to all fields",
        "Create get_settings() function that returns cached Settings instance",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 3,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-004",
      "title": "Create Gemini client initialization with error handling",
      "description": "As a developer, I need a Gemini API client that handles authentication and connection errors gracefully.",
      "acceptanceCriteria": [
        "Create app/services/gemini_client.py",
        "Import: from google import genai (NOT google.generativeai)",
        "Create get_gemini_client() function that returns genai.Client()",
        "Handle missing API key with clear error: 'GEMINI_API_KEY not set in environment'",
        "Add docstrings explaining client initialization",
        "Add type hints: def get_gemini_client() -> genai.Client",
        "Typecheck passes",
        "Tests pass (with mocked client)"
      ],
      "priority": 4,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-005",
      "title": "Create Pydantic models for extraction results",
      "description": "As a developer, I need data models for PDF extraction results with validation.",
      "acceptanceCriteria": [
        "Create app/models/extraction.py",
        "Create BoundingBox(BaseModel): x1, y1, x2, y2 (floats), page (int)",
        "Create ExtractedMetadata(BaseModel): title, authors (List[str]), journal, year, doi (all Optional except title)",
        "Create ExtractedSection(BaseModel): heading, content, page_number, bbox (Optional[BoundingBox])",
        "Create ExtractedTable(BaseModel): caption, page_number, data (List[dict]), bbox (Optional[BoundingBox])",
        "Create ExtractedReference(BaseModel): citation_text, authors, year, title",
        "Create DocumentStructure(BaseModel): markdown (str), tables (List[dict]), bounding_boxes (dict), quality_score (float), element_count (int)",
        "Create ExtractionResult(BaseModel): metadata, abstract (Optional[str]), sections, tables, references, confidence_score, bounding_boxes, processing_metadata (dict)",
        "Add Field validators where appropriate (e.g., confidence_score between 0-1)",
        "Typecheck passes",
        "Tests pass (model validation tests)"
      ],
      "priority": 5,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-006",
      "title": "Implement OpenDataLoader PDF structure extraction",
      "description": "As a developer, I need to extract PDF structure locally using OpenDataLoader before sending to Gemini.",
      "acceptanceCriteria": [
        "Create app/services/opendataloader_extractor.py",
        "Implement extract_pdf_structure(file_path: str) -> DocumentStructure",
        "Use DocumentLoader from opendataloader_pdf to load PDF",
        "Extract markdown: doc.export_to_markdown()",
        "Extract tables: doc.get_tables() with caption, page, data, bbox",
        "Extract bounding boxes for all elements: store in dict keyed by element_id",
        "Calculate element_count from len(doc.elements)",
        "Handle errors gracefully: catch exceptions and raise with clear message",
        "Add type hints to all functions",
        "Add docstrings explaining the extraction process",
        "Typecheck passes",
        "Tests pass (with sample PDF fixture)"
      ],
      "priority": 6,
      "passes": true,
      "notes": ""
    },
    {
      "id": "US-007",
      "title": "Implement quality scoring for routing decisions",
      "description": "As a developer, I need to calculate quality scores to decide between hybrid and Vision fallback modes.",
      "acceptanceCriteria": [
        "Create calculate_quality_score(doc) -> float function in opendataloader_extractor.py",
        "Score based on text completeness (40%): >1000 chars = 0.4, >500 = 0.3, >100 = 0.2",
        "Score based on structure (30%): >50 elements = 0.3, >20 = 0.2, >5 = 0.1",
        "Score based on headings (15%): >=5 headings = 0.15, >=3 = 0.1, >=1 = 0.05",
        "Score based on tables (15%): valid tables (>3 rows) = 0.15, some tables = 0.1",
        "Return min(score, 1.0) to cap at 1.0",
        "Update extract_pdf_structure to call calculate_quality_score and include in result",
        "Add type hints and docstrings",
        "Typecheck passes",
        "Tests pass (test quality scoring with various PDFs)"
      ],
      "priority": 7,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-008",
      "title": "Implement hybrid extraction pipeline (OpenDataLoader + Gemini)",
      "description": "As a developer, I need the core hybrid extraction function that routes through OpenDataLoader then Gemini.",
      "acceptanceCriteria": [
        "Create app/services/pdf_extractor.py",
        "Implement extract_pdf_data_hybrid(client, file_path, model) -> ExtractionResult",
        "Step 1: Call extract_pdf_structure(file_path)",
        "Step 2: If quality_score < 0.7, call extract_with_vision_fallback (stub for now, implement later)",
        "Step 3: Build prompt with markdown content asking Gemini to extract metadata, abstract, sections, references",
        "Step 4: Call client.models.generate_content with response_schema=ExtractionResult",
        "Step 5: Merge result.tables from OpenDataLoader with Gemini semantic data",
        "Step 6: Add processing_metadata: {'method': 'hybrid', 'opendataloader_quality': quality_score, 'cost_savings_percent': 80}",
        "Add type hints to all functions",
        "Typecheck passes",
        "Tests pass (with mocked Gemini client and sample PDF)"
      ],
      "priority": 8,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-009",
      "title": "Implement Vision fallback for low-quality PDFs",
      "description": "As a developer, I need a fallback to Gemini Vision API when OpenDataLoader extraction quality is too low.",
      "acceptanceCriteria": [
        "Implement extract_with_vision_fallback(client, file_path, model) in pdf_extractor.py",
        "Upload file using client.files.upload(file=file_path)",
        "Call client.models.generate_content with uploaded file and extraction prompt",
        "Use response_schema=ExtractionResult for structured output",
        "Delete uploaded file in finally block: client.files.delete(name=uploaded_file.name)",
        "Add processing_metadata: {'method': 'vision_fallback', 'reason': 'Low OpenDataLoader quality score'}",
        "Add type hints and docstrings",
        "Typecheck passes",
        "Tests pass (with mocked Gemini File API)"
      ],
      "priority": 9,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-010",
      "title": "Implement file upload validation",
      "description": "As a developer, I need to validate PDF uploads for security and integrity.",
      "acceptanceCriteria": [
        "Create app/services/file_validator.py",
        "Implement validate_pdf(file: UploadFile) -> bytes function",
        "Check file size: max 200MB (return 413 if exceeded)",
        "Check file not empty: return 400 if 0 bytes",
        "Validate MIME type using python-magic: must be 'application/pdf' (return 400 if not)",
        "Sanitize filename: remove path traversal characters (../, etc.)",
        "Calculate SHA-256 hash of file content for deduplication",
        "Return tuple: (content: bytes, file_hash: str, sanitized_filename: str)",
        "Add type hints and docstrings",
        "Typecheck passes",
        "Tests pass (test various invalid file scenarios)"
      ],
      "priority": 10,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-011",
      "title": "Create Supabase client initialization",
      "description": "As a developer, I need a Supabase client to connect to the database.",
      "acceptanceCriteria": [
        "Create app/db/supabase_client.py",
        "Import from supabase import create_client, Client",
        "Create get_supabase_client() -> Client function",
        "Load SUPABASE_URL and SUPABASE_KEY from Settings",
        "Return create_client(url, key)",
        "Handle missing credentials with clear error messages",
        "Add type hints and docstrings",
        "Typecheck passes",
        "Tests pass (with mocked Supabase client)"
      ],
      "priority": 11,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-012",
      "title": "Create database schema migration for extractions table",
      "description": "As a developer, I need a database schema to store extraction results with bounding boxes.",
      "acceptanceCriteria": [
        "Create migrations/001_create_extractions_table.sql",
        "Create table: extractions with UUID id (primary key)",
        "Add columns: file_name (text), file_size_bytes (bigint), file_hash (text unique)",
        "Add: status (enum: pending, completed, failed, partial), processing_method (enum: hybrid, vision_fallback, opendataloader_only)",
        "Add: quality_score (decimal), confidence_score (decimal)",
        "Add JSONB columns: metadata, sections, figures, tables, references, bounding_boxes",
        "Add: abstract (text), error_message (text nullable), processing_time_seconds (decimal), cost_estimate_usd (decimal)",
        "Add timestamps: created_at (default now()), updated_at",
        "Add: webhook_url (text nullable), retry_count (integer default 0)",
        "Create indexes: file_hash (unique), status, created_at, processing_method",
        "Document schema in comments"
      ],
      "priority": 12,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-013",
      "title": "Implement database storage functions for extractions",
      "description": "As a developer, I need functions to insert and query extraction results in Supabase.",
      "acceptanceCriteria": [
        "Create app/db/extractions.py",
        "Implement create_extraction(client, data: ExtractionResult, file_info: dict) -> str (returns UUID)",
        "Implement get_extraction(client, extraction_id: str) -> Optional[ExtractionResult]",
        "Implement check_duplicate(client, file_hash: str) -> Optional[str] (returns existing extraction_id)",
        "Implement update_extraction_status(client, extraction_id: str, status: str, error: Optional[str])",
        "Implement list_extractions(client, limit: int, offset: int, status: Optional[str]) -> List[dict]",
        "All functions use async/await for Supabase operations",
        "Handle errors gracefully: return None for not found, raise for database errors",
        "Add type hints to all functions",
        "Typecheck passes",
        "Tests pass (with mocked Supabase client)"
      ],
      "priority": 13,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-014",
      "title": "Create FastAPI app with health check endpoint",
      "description": "As a developer, I need a FastAPI application with health monitoring.",
      "acceptanceCriteria": [
        "Create app/main.py with FastAPI() app instance",
        "Add CORS middleware from fastapi.middleware.cors",
        "Add GET /health endpoint that returns JSON: {status, timestamp, services: {opendataloader, gemini_api, supabase}}",
        "Test OpenDataLoader by attempting to import DocumentLoader",
        "Test Gemini by checking get_gemini_client() doesn't raise",
        "Test Supabase by calling client.table('extractions').select('id').limit(1)",
        "Return 200 if all healthy, 503 if any fail",
        "Add @app.on_event('startup') to validate env vars",
        "Enable Swagger docs at /docs",
        "Add GET /version endpoint returning {version, commit_hash}",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 14,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-015",
      "title": "Create PDF extraction endpoint (POST /extract)",
      "description": "As an API consumer, I need an endpoint to upload a PDF and get extraction results.",
      "acceptanceCriteria": [
        "Create app/routers/extraction.py with APIRouter",
        "Add POST /extract endpoint accepting multipart/form-data",
        "Accept file parameter (UploadFile) and optional webhook_url",
        "Call validate_pdf() to validate upload",
        "Check for duplicate using file_hash",
        "Save file temporarily to disk",
        "Call extract_pdf_data_hybrid()",
        "Store result using create_extraction()",
        "Return 201 with extraction result JSON",
        "Add X-Extraction-ID header with UUID",
        "Handle errors: 400 for validation, 413 for too large, 422 for corrupted PDF, 500 for processing errors",
        "Clean up temporary file in finally block",
        "Add router to main.py: app.include_router(extraction.router)",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 15,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-016",
      "title": "Create extraction retrieval endpoint (GET /extractions/{id})",
      "description": "As an API consumer, I need to retrieve extraction results by ID.",
      "acceptanceCriteria": [
        "Add GET /extractions/{extraction_id} endpoint to extraction.py router",
        "Validate extraction_id is valid UUID format (return 400 if not)",
        "Call get_extraction(extraction_id)",
        "Return 404 if not found",
        "Return 200 with extraction result JSON if found",
        "Include bounding_boxes in response",
        "Include processing_metadata (method, quality_score, etc.)",
        "Add GET /extractions endpoint with pagination: query params limit (default 50), offset (default 0), status filter",
        "Return list of extractions with total count",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 16,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-017",
      "title": "Create bounding box retrieval endpoints",
      "description": "As a researcher, I need to retrieve bounding box coordinates for citation features.",
      "acceptanceCriteria": [
        "Add GET /extractions/{id}/bounding-boxes endpoint",
        "Return all bounding boxes for the extraction as JSON dict",
        "Add GET /extractions/{id}/elements/{element_id} endpoint",
        "Return specific element with its bounding box and content",
        "Return 404 if extraction_id or element_id not found",
        "Include element_type in response (heading, paragraph, table, etc.)",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 17,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-018",
      "title": "Implement retry logic with exponential backoff",
      "description": "As a developer, I need automatic retry for transient Gemini API failures.",
      "acceptanceCriteria": [
        "Create app/utils/retry.py",
        "Implement retry_with_backoff decorator",
        "Retry on: 429 (rate limit), 503 (unavailable), 500 (server error), network timeouts",
        "Do NOT retry on: 400 (bad request), 401 (auth), 404 (not found)",
        "Exponential backoff: 1s, 2s, 4s, 8s, 16s (max 5 retries)",
        "Add random jitter (0-1s) to prevent thundering herd",
        "Log each retry attempt with attempt number",
        "Apply decorator to Gemini API calls in pdf_extractor.py",
        "Typecheck passes",
        "Tests pass (mock API failures)"
      ],
      "priority": 18,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-019",
      "title": "Implement partial result storage",
      "description": "As a researcher, I need partial extraction results saved when processing fails mid-way.",
      "acceptanceCriteria": [
        "Update create_extraction to accept status parameter (default 'completed')",
        "In extract_pdf_data_hybrid, wrap Gemini call in try/except",
        "On exception: save what was extracted from OpenDataLoader with status='partial'",
        "Set error_message field with exception details",
        "Store partial data: tables from OpenDataLoader, bounding_boxes, quality_score",
        "Add POST /extractions/{id}/retry endpoint to re-process partial extractions",
        "Merge new data with existing partial data on retry",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 19,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-020",
      "title": "Add request logging and metrics",
      "description": "As a DevOps engineer, I need structured logging for monitoring and debugging.",
      "acceptanceCriteria": [
        "Create app/middleware/logging.py",
        "Add middleware that logs: timestamp, request_id, method, path, status_code, processing_time_ms, user_ip",
        "Log routing decisions: processing_method (hybrid vs vision_fallback), quality_score",
        "Use JSON format for logs with structlog or Python logging",
        "Never log: API keys, file contents, sensitive user data",
        "Add request_id to all log entries (generate UUID per request)",
        "Log errors with full stack trace",
        "Add middleware to app in main.py",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 20,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-021",
      "title": "Add rate limiting middleware",
      "description": "As a system administrator, I need rate limiting to prevent abuse.",
      "acceptanceCriteria": [
        "Create app/middleware/rate_limit.py",
        "Use slowapi or similar library for rate limiting",
        "Limits: POST /extract = 10 req/min per IP, POST /batch = 2 req/min, GET /extractions = 100 req/min",
        "Return 429 with Retry-After header when limit exceeded",
        "Add X-RateLimit-Remaining header to all responses",
        "Use in-memory storage for MVP (can upgrade to Redis later)",
        "Add middleware to app in main.py",
        "Typecheck passes",
        "Tests pass (test rate limit enforcement)"
      ],
      "priority": 21,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-022",
      "title": "Create manual review queue for failed extractions",
      "description": "As a data quality manager, I need failed extractions queued for manual review.",
      "acceptanceCriteria": [
        "Create migrations/002_create_review_queue_table.sql",
        "Create table: review_queue with UUID id, extraction_id (FK), error_type, error_message",
        "Add: processing_method, quality_score, retry_count, queued_at, reviewed_at (nullable), reviewer_notes (nullable)",
        "Add resolution enum: fixed, false_positive, unable_to_process",
        "Update extraction endpoint: when retry_count > 5, add to review_queue",
        "Add GET /review-queue endpoint (returns pending items)",
        "Add POST /review-queue/{id}/resolve endpoint (marks as reviewed)",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 22,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-023",
      "title": "Implement batch processing endpoint",
      "description": "As a researcher, I need to upload multiple PDFs for batch processing.",
      "acceptanceCriteria": [
        "Create migrations/003_create_batch_jobs_table.sql",
        "Create table: batch_jobs with UUID id, total_files, completed_files, failed_files, status",
        "Add JSONB: routing_stats {hybrid, vision_fallback, pending}, extraction_ids (array)",
        "Add: created_at, estimated_completion, cost_estimate_usd, cost_savings_usd, webhook_url",
        "Add POST /batch endpoint accepting multiple files (max 100)",
        "Generate batch_job_id, store in database",
        "Process each file through hybrid pipeline (can be synchronous for MVP)",
        "Update batch_jobs.routing_stats as files complete",
        "Return 202 with batch_job_id and status URL",
        "Add GET /batch/{job_id} endpoint for status checking",
        "Typecheck passes",
        "Tests pass (small batch of 3-5 files)"
      ],
      "priority": 23,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-024",
      "title": "Implement webhook notifications",
      "description": "As an API consumer, I need webhook notifications when extraction completes.",
      "acceptanceCriteria": [
        "Create app/services/webhook_sender.py",
        "Implement send_webhook(webhook_url, payload, signature_key) function",
        "Validate webhook_url is HTTPS (reject HTTP)",
        "Generate HMAC-SHA256 signature of payload",
        "Add X-Webhook-Signature header",
        "POST payload to webhook_url with 30s timeout",
        "Retry on failure: 3 retries with exponential backoff",
        "Log webhook delivery attempts and responses",
        "Call send_webhook after successful extraction if webhook_url provided",
        "Payload format: {event: 'extraction.completed', extraction_id, status, data, timestamp}",
        "Typecheck passes",
        "Tests pass (with mock webhook server)"
      ],
      "priority": 24,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-025",
      "title": "Implement context caching for cost optimization",
      "description": "As a cost-conscious operator, I need Gemini context caching to reduce API costs by 90%.",
      "acceptanceCriteria": [
        "Update pdf_extractor.py to use context caching",
        "Cache system instruction prompt for academic PDF analysis",
        "Set cache TTL to 1 hour",
        "Track cache hits/misses in processing_metadata",
        "Calculate cost savings: add cached_tokens_saved to metadata",
        "Log cache statistics per request",
        "Add GET /stats/caching endpoint showing cache hit rate and savings",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 25,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-026",
      "title": "Add routing statistics dashboard endpoint",
      "description": "As an operator, I need to see routing distribution and cost savings metrics.",
      "acceptanceCriteria": [
        "Add GET /stats/routing endpoint",
        "Query extractions table: count by processing_method",
        "Calculate average quality_score",
        "Calculate total_cost_usd, estimated_pure_vision_cost_usd, total_savings_usd, savings_percent",
        "Calculate performance metrics: avg_processing_time_seconds, p95_processing_time",
        "Return JSON with all metrics",
        "Cache results for 5 minutes to reduce database load",
        "Typecheck passes",
        "Tests pass"
      ],
      "priority": 26,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-027",
      "title": "Create integration tests for end-to-end extraction flow",
      "description": "As a developer, I need integration tests to verify the complete extraction pipeline works.",
      "acceptanceCriteria": [
        "Create tests/integration/test_extraction_flow.py",
        "Test: upload PDF → extract (hybrid) → store → retrieve → verify bounding boxes",
        "Test: upload scanned PDF → fallback to Vision → store → retrieve",
        "Test: upload duplicate PDF → return cached result",
        "Test: upload invalid file → return 400 error",
        "Test: batch processing with 3 PDFs → verify all complete",
        "Test: webhook delivery after extraction",
        "Use pytest fixtures for: test PDFs, mock Gemini client, test Supabase instance",
        "Tests pass",
        "Coverage > 80% for core extraction flow"
      ],
      "priority": 27,
      "passes": false,
      "notes": ""
    },
    {
      "id": "US-028",
      "title": "Create deployment documentation and Docker configuration",
      "description": "As a DevOps engineer, I need deployment instructions and containerization.",
      "acceptanceCriteria": [
        "Create Dockerfile: FROM python:3.11-slim",
        "Install dependencies from requirements.txt",
        "Set working directory to /app",
        "Copy app code",
        "Expose port 8000",
        "CMD: uvicorn app.main:app --host 0.0.0.0 --port 8000",
        "Create docker-compose.yml for local development (includes app service)",
        "Create DEPLOYMENT.md with: environment setup, Docker build/run, environment variables, health check verification",
        "Document Supabase setup steps (create project, run migrations)",
        "Document how to get Gemini API key",
        "All documentation clear and tested"
      ],
      "priority": 28,
      "passes": false,
      "notes": ""
    }
  ]
}
